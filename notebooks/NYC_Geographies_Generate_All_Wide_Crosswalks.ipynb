{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Note: This notebook now delegates to the reusable CLI\n",
        "\n",
        "Use `scripts/build_crosswalks.py` to generate all wide/long crosswalk files for the latest run folder created by `generate_all_bounds.py` or `scripts/make_run.py`. See the code cell below to execute it from this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, glob, subprocess\n",
        "\n",
        "runs = sorted([d for d in glob.glob('outputs/*') if os.path.isdir(d)])\n",
        "if not runs:\n",
        "    raise RuntimeError(\"No outputs/<run-id>/ found. Run generate_all_bounds.py or scripts/make_run.py first.\")\n",
        "latest = runs[-1]\n",
        "\n",
        "boundaries = os.path.join(latest, 'all_boundaries.geojson')\n",
        "if not os.path.isfile(boundaries):\n",
        "    raise RuntimeError(f\"Missing {boundaries}. Run bounds step first.\")\n",
        "\n",
        "print(f\"Using run folder: {latest}\")\n",
        "cmd = [\n",
        "    'python', 'scripts/build_crosswalks.py',\n",
        "    '--boundaries', boundaries,\n",
        "    '--run-dir', latest,\n",
        "]\n",
        "print('Running:', ' '.join(cmd))\n",
        "subprocess.run(cmd, check=True)\n",
        "print('Crosswalks built. See longform/ and wide/ under', latest)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MODA-NYC/nyc-geography-crosswalks/blob/main/NYC_Geographies_Generate_All_Wide_Crosswalks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTzgStBoAqbv"
      },
      "source": [
        "# NYC Geographies: Generate All Wide-Format Crosswalks\n",
        "\n",
        "This notebook automates the generation of a complete set of **wide-format** geographic crosswalk tables for New York City. It processes all defined geographic boundaries using the `all_boundaries.geojson` file generated by the `generate_all_bounds.py` script.\n",
        "\n",
        "**Important:** This notebook relies on the `all_boundaries.geojson` file being generated first by the `generate_all_bounds.py` script located within this repository (`nyc-geography-crosswalks`). Ensure you have run that script and have access to its output file before running this notebook.\n",
        "\n",
        "**About the Input Data File:**\n",
        "The `all_boundaries.geojson` file used as input aggregates the same core NYC geographic boundaries previously used by the BetaNYC Boundaries Map project. The `generate_all_bounds.py` script aims to collect the **latest available versions** directly from their official sources at the time the script is run.\n",
        "\n",
        "*   **Note on Versions:** Currently, the specific version links (e.g., URLs containing `_25a` for data from NYC Planning's 2025 Cycle A update) are **hardcoded** within the generator script (`generate_all_bounds.py`).\n",
        "*   **Future Enhancement:** A potential future improvement could involve modifying the generator script to automatically check for and download the absolute latest versions available from the source portals.\n",
        "\n",
        "### What this notebook does:\n",
        "1.  **Load Data:** Loads the pre-generated `all_boundaries.geojson` file (typically from Google Drive when using Colab - see Cell 3).\n",
        "2.  **Iterate:** Loops through each defined geography type as the \"primary\" geography.\n",
        "3.  **Spatial Intersections:** For each primary feature, computes overlaps with all features from *other* relevant geography types using GeoPandas.\n",
        "4.  **Negative Buffering:** Applies a negative buffer to each primary geography feature during the intersection check to ensure only significant overlaps are included and trivial or merely touching geometries are excluded.\n",
        "5.  **Generate Wide CSVs:** Produces **one CSV file per primary geography type** (e.g., `wide_cd_crosswalk.csv`, `wide_pp_crosswalk.csv`). Each CSV is structured as a wide table where:\n",
        "    *   Each **row** represents a specific feature of the primary geography type (e.g., one Community District).\n",
        "    *   Each **column** represents another geography type, containing a semicolon-separated list of the `nameCol` identifiers of the overlapping features from that type.\n",
        "6.  **Package Output:** Zips all generated wide-format CSV files from the current run into a single downloadable archive.\n",
        "\n",
        "### Data Sources:\n",
        "The **input** for *this notebook* is the `all_boundaries.geojson` file generated by the `generate_all_bounds.py` script. The **original sources** used by that script are:\n",
        "\n",
        "*   **cd (Community Districts):** NYC Department of City Planning (DCP)\n",
        "*   **pp (Police Precincts):** NYC Department of City Planning (DCP)\n",
        "*   **dsny (Sanitation Districts):** NYC Open Data (Dataset ID: i6mn-amj2)\n",
        "*   **fb (Fire Battalions):** NYC Department of City Planning (DCP)\n",
        "*   **sd (School Districts):** NYC Department of City Planning (DCP)\n",
        "*   **hc (Health Center Districts):** NYC Department of City Planning (DCP)\n",
        "*   **cc (City Council Districts):** NYC Department of City Planning (DCP)\n",
        "*   **nycongress (Congressional Districts):** NYC Department of City Planning (DCP)\n",
        "*   **sa (State Assembly Districts):** NYC Department of City Planning (DCP)\n",
        "*   **ss (State Senate Districts):** NYC Department of City Planning (DCP)\n",
        "*   **bid (Business Improvement Districts):** NYC Open Data (Dataset ID: 7jdm-inj8 / derived from ejxk-d93y)\n",
        "*   **nta (Neighborhood Tabulation Areas):** NYC Department of City Planning (DCP - NTA 2020)\n",
        "*   **zipcode (Modified Zip Code Tabulation Areas):** NYC Open Data (Dataset ID: pri4-ifjk)\n",
        "*   **hd (Historic Districts):** NYC Open Data (Dataset ID: skyk-mpzq / derived from xbvj-gfnw)\n",
        "*   **ibz (Industrial Business Zones):** NYC Economic Development Corporation (EDC)\n",
        "\n",
        "*Context for many planning datasets can be found at:*\n",
        "*   [NYC Planning - Bytes of the Big Apple](https://www.nyc.gov/site/planning/data-maps/open-data/bytes-big-apple.page)\n",
        "*   [NYC Open Data Portal](https://data.cityofnewyork.us/)\n",
        "\n",
        "### Requirements:\n",
        "- **Prerequisite:** Successful execution of `generate_all_bounds.py` and access to its output `all_boundaries.geojson`.\n",
        "- **Python Libraries:** `geopandas`, `pandas`, `tqdm`, `google.colab` (for Drive/files), `os`, `zipfile`. `requests` is needed if using the URL loading method for the data file.\n",
        "- **Environment:** Google Colab is recommended for Google Drive integration. Standard Python environments can also be used if data loading is adapted.\n",
        "\n",
        "### Output:\n",
        "- **ZIP file:** `all_geographies_wide_crosswalks.zip` (or similar name generated by the script) containing individual wide-format CSV files, one for each primary geography type processed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_coes7FVMs1"
      },
      "source": [
        "## 1: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TexYJkTsVOlj"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Install Dependencies\n",
        "# Install required libraries if running in a new environment\n",
        "print(\"Installing dependencies...\")\n",
        "!pip install geopandas pandas requests tqdm --quiet\n",
        "# Note: requests might not be strictly needed if only using Drive method, but safe to include.\n",
        "# Note: tqdm added for potential future progress bars if desired. ipywidgets not needed here.\n",
        "print(\"Dependencies installed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVK8PWy7VSAL"
      },
      "source": [
        "## 2: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAllTyEWWT46"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Import Libraries\n",
        "# Import necessary libraries for the entire notebook\n",
        "print(\"Importing libraries...\")\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import requests # Needed only if using URL method for data loading\n",
        "from io import BytesIO # Needed only if using URL method for data loading\n",
        "from google.colab import drive # For loading from Google Drive\n",
        "from google.colab import files # For downloading results\n",
        "import zipfile # For packaging results\n",
        "from tqdm.notebook import tqdm # Progress bar (added import)\n",
        "import os\n",
        "# Import Union for type hints if needed\n",
        "# from typing import Union\n",
        "print(\"Libraries imported.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baULLL6lWWXy"
      },
      "source": [
        "## 3: Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PiIpybGWbPy"
      },
      "outputs": [],
      "source": [
        "# Cell 3: Load and Prepare Data\n",
        "# --- Load and Prepare the Master GeoDataFrame ---\n",
        "\n",
        "# Choose ONE of the methods below to load all_boundaries.geojson:\n",
        "\n",
        "# --- Method 1: Load from Google Drive (Currently Active for Testing) ---\n",
        "print(\"Attempting to mount Google Drive...\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# !!!! IMPORTANT: Replace this path with the ACTUAL path to your file on Google Drive !!!!\n",
        "geojson_path_on_drive = '/content/drive/MyDrive/Projects/ODA/Crosswalk Experiment/all_boundaries.geojson' # <--- USE YOUR CORRECT PATH HERE\n",
        "\n",
        "gdf = None # Initialize gdf\n",
        "if not os.path.exists(geojson_path_on_drive):\n",
        "  print(f\"ERROR: File not found at specified Google Drive path: {geojson_path_on_drive}\")\n",
        "  print(\"Please double-check the path and ensure the file exists.\")\n",
        "else:\n",
        "  print(f\"Found file at: {geojson_path_on_drive}\")\n",
        "  try:\n",
        "      print(\"Reading GeoJSON from Google Drive...\")\n",
        "      gdf_loaded = gpd.read_file(geojson_path_on_drive)\n",
        "      print(f\"Successfully read file. Original CRS: {gdf_loaded.crs}\")\n",
        "\n",
        "      # Reproject to EPSG:2263 for buffer calculations in this notebook (feet)\n",
        "      print(\"Reprojecting to EPSG:2263 (Feet)...\")\n",
        "      gdf = gdf_loaded.to_crs(epsg=2263)\n",
        "      print(f\"Successfully loaded and reprojected GeoDataFrame. New CRS: {gdf.crs}\")\n",
        "\n",
        "      # Create Spatial Index for faster lookups\n",
        "      if gdf.sindex is None:\n",
        "          print(\"Generating spatial index for gdf...\")\n",
        "          gdf.sindex # This builds the index\n",
        "\n",
        "      print(\"\\nGeoDataFrame Info:\")\n",
        "      print(gdf.info())\n",
        "\n",
        "  except Exception as e:\n",
        "      print(f\"ERROR: Failed to read or reproject GeoJSON from Google Drive. Error: {e}\")\n",
        "      # raise e # Uncomment to stop execution on error\n",
        "\n",
        "# --- End Method 1 ---\n",
        "\n",
        "\n",
        "# --- Method 2: Load from URL (Currently Commented Out) ---\n",
        "# # !!!! IMPORTANT: Replace this URL with the ACTUAL download URL for your GeoJSON file !!!!\n",
        "# geojson_url = \"YOUR_GEOJSON_DOWNLOAD_URL_HERE\" # <--- CHANGE THIS\n",
        "\n",
        "# gdf = None # Initialize gdf\n",
        "# try:\n",
        "#     print(f\"Attempting to download GeoJSON from URL: {geojson_url}\")\n",
        "#     response = requests.get(geojson_url, timeout=60)\n",
        "#     response.raise_for_status()\n",
        "#     print(\"Download successful. Reading GeoJSON...\")\n",
        "\n",
        "#     gdf_loaded = gpd.read_file(BytesIO(response.content))\n",
        "#     print(f\"Successfully read file. Original CRS: {gdf_loaded.crs}\")\n",
        "\n",
        "#     print(\"Reprojecting to EPSG:2263 (Feet)...\")\n",
        "#     gdf = gdf_loaded.to_crs(epsg=2263)\n",
        "#     print(f\"Successfully loaded and reprojected GeoDataFrame. New CRS: {gdf.crs}\")\n",
        "\n",
        "#     if gdf.sindex is None:\n",
        "#         print(\"Generating spatial index for gdf...\")\n",
        "#         gdf.sindex # Build index\n",
        "\n",
        "#     print(\"\\nGeoDataFrame Info:\")\n",
        "#     print(gdf.info())\n",
        "\n",
        "# except requests.exceptions.RequestException as e:\n",
        "#     print(f\"ERROR: Failed to download GeoJSON from URL. Error: {e}\")\n",
        "# except Exception as e:\n",
        "#     print(f\"ERROR: Failed to read or reproject GeoJSON from downloaded data. Error: {e}\")\n",
        "#     # raise e # Uncomment to stop execution on error\n",
        "\n",
        "# --- End Method 2 ---\n",
        "\n",
        "\n",
        "# --- Final Verification ---\n",
        "if 'gdf' not in locals() or gdf is None or not isinstance(gdf, gpd.GeoDataFrame) or gdf.empty:\n",
        "    raise ValueError(\"ERROR: GeoDataFrame 'gdf' was not loaded successfully in Cell 3. Cannot proceed.\")\n",
        "else:\n",
        "    print(\"\\nGeoDataFrame 'gdf' is loaded, prepared, and ready for use in subsequent cells.\")\n",
        "\n",
        "# --- Define Geography IDs list globally for use in next cell ---\n",
        "# (Corrected list based on previous steps)\n",
        "geography_ids = ['pp', 'fb', 'sd', 'bid', 'ibz', 'cd', 'dsny', 'hc',\n",
        "                 'cc', 'nycongress', 'sa', 'ss', 'nta', 'zipcode', 'hd']\n",
        "print(f\"\\nGeography IDs available for crosswalks: {geography_ids}\")\n",
        "\n",
        "# --- Configuration (moved here for clarity) ---\n",
        "BUFFER_FEET = -200\n",
        "MIN_INTERSECTION_AREA = 400\n",
        "print(f\"\\nConfiguration: Buffer={BUFFER_FEET}ft, Min Intersection Area={MIN_INTERSECTION_AREA}sqft\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9omDnsuDWhnp"
      },
      "source": [
        "## 4: Generate All Wide-Format Crosswalks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXs1z1mcWlHp"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Generate All Wide-Format Crosswalks\n",
        "\n",
        "# Check if prerequisites exist from previous cell\n",
        "if 'gdf' not in locals() or gdf is None:\n",
        "     raise NameError(\"ERROR: GeoDataFrame 'gdf' is not available. Please run the 'Load and Prepare Data' cell first.\")\n",
        "if 'geography_ids' not in locals():\n",
        "     raise NameError(\"ERROR: 'geography_ids' list not found. Please run the 'Load and Prepare Data' cell first.\")\n",
        "if gdf.sindex is None: # Ensure spatial index exists\n",
        "    print(\"Warning: Spatial index not found on gdf. Generating now...\")\n",
        "    gdf.sindex\n",
        "if 'BUFFER_FEET' not in locals() or 'MIN_INTERSECTION_AREA' not in locals():\n",
        "     raise NameError(\"ERROR: Configuration variables (BUFFER_FEET, MIN_INTERSECTION_AREA) not found.\")\n",
        "\n",
        "\n",
        "print(\"Starting generation of all wide-format crosswalks...\")\n",
        "\n",
        "# --- Output Setup ---\n",
        "output_folder = 'wide_crosswalks_consolidated' # Use a distinct folder name\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "print(f\"Output CSVs will be saved to: {output_folder}\")\n",
        "csv_files_generated = [] # Keep track of generated files\n",
        "\n",
        "# Use the spatial index from the globally loaded gdf\n",
        "spatial_index = gdf.sindex\n",
        "\n",
        "# --- Main Loop ---\n",
        "for primary_geo in tqdm(geography_ids, desc=\"Primary Geographies\"):\n",
        "    # Use global gdf\n",
        "    primary_gdf = gdf[gdf['id'] == primary_geo].copy()\n",
        "    if primary_gdf.empty:\n",
        "        print(f\"Skipping primary geography '{primary_geo}' - no features found.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nProcessing Primary Geography: {primary_geo}\")\n",
        "    records = [] # Reset records for each primary geography\n",
        "\n",
        "    # Iterate through each primary feature\n",
        "    for _, primary_row in tqdm(primary_gdf.iterrows(), total=primary_gdf.shape[0], desc=f\"Features in {primary_geo}\", leave=False):\n",
        "        primary_name = primary_row['nameCol']\n",
        "        primary_geom_buffered = primary_row.geometry.buffer(BUFFER_FEET)\n",
        "\n",
        "        # Find candidates intersecting the buffered primary feature\n",
        "        candidate_idx = list(spatial_index.intersection(primary_geom_buffered.bounds))\n",
        "        # Use global gdf\n",
        "        candidate_features = gdf.iloc[candidate_idx]\n",
        "\n",
        "        # Filter for actual intersection with the buffer\n",
        "        mask = candidate_features.intersects(primary_geom_buffered)\n",
        "        candidates = candidate_features[mask].copy()\n",
        "\n",
        "        # Calculate intersection area with the buffer and filter by minimum area\n",
        "        if not candidates.empty:\n",
        "            candidates['intersection_area'] = candidates.geometry.intersection(primary_geom_buffered).area\n",
        "            final_candidates = candidates[candidates['intersection_area'] > MIN_INTERSECTION_AREA]\n",
        "        else:\n",
        "            final_candidates = candidates # Pass empty frame\n",
        "\n",
        "        # Build the record for this primary feature\n",
        "        record = {primary_geo: primary_name}\n",
        "\n",
        "        # Add columns for all other geography types\n",
        "        for secondary_geo in geography_ids:\n",
        "            if secondary_geo == primary_geo:\n",
        "                continue  # skip self-intersection column\n",
        "\n",
        "            # Check if 'id' column exists in final_candidates\n",
        "            if 'id' not in final_candidates.columns:\n",
        "                # This shouldn't happen if gdf is structured correctly, but safe check\n",
        "                print(f\"Warning: 'id' column missing in candidates for primary {primary_geo}. Setting target {secondary_geo} to empty.\")\n",
        "                record[secondary_geo] = \"\"\n",
        "                continue\n",
        "\n",
        "            subset = final_candidates[final_candidates['id'] == secondary_geo]\n",
        "\n",
        "            # Check if 'nameCol' exists before trying to access it\n",
        "            if not subset.empty and 'nameCol' in subset.columns:\n",
        "               # Get unique, non-null string representations\n",
        "               unique_names = subset['nameCol'].dropna().astype(str).unique()\n",
        "               record[secondary_geo] = \";\".join(unique_names) if len(unique_names) > 0 else \"\"\n",
        "            else:\n",
        "               record[secondary_geo] = \"\"\n",
        "\n",
        "        records.append(record)\n",
        "    # --- End loop for primary features ---\n",
        "\n",
        "    # --- Save the consolidated CSV for the current primary_geo ---\n",
        "    if records:\n",
        "        df = pd.DataFrame(records)\n",
        "        # Define column order: primary first, then others alphabetically maybe?\n",
        "        cols = [primary_geo] + sorted([g for g in geography_ids if g != primary_geo])\n",
        "        df = df[cols] # Reorder columns\n",
        "\n",
        "        filename = f\"{output_folder}/wide_{primary_geo}_crosswalk.csv\"\n",
        "        try:\n",
        "            df.to_csv(filename, index=False)\n",
        "            csv_files_generated.append(filename)\n",
        "            print(f\"Saved consolidated file: {filename} ({len(df)} rows)\")\n",
        "        except Exception as save_e:\n",
        "            print(f\"ERROR saving {filename}: {save_e}\")\n",
        "    else:\n",
        "        print(f\"No records generated for primary geography {primary_geo}. No CSV generated.\")\n",
        "\n",
        "# --- End loop for primary geographies ---\n",
        "\n",
        "print(f\"\\nFinished generating all wide-format crosswalk CSVs in folder: {output_folder}\")\n",
        "print(f\"Generated {len(csv_files_generated)} files.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drHwoIk4WohZ"
      },
      "source": [
        "## 5: Package and Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuuCucAIWs7R"
      },
      "outputs": [],
      "source": [
        "# Cell 5: Package and Download Results\n",
        "\n",
        "# Check if csv_files_generated exists and has files\n",
        "if 'csv_files_generated' not in locals() or not csv_files_generated:\n",
        "    print(\"No CSV files were generated in the previous step, skipping packaging.\")\n",
        "else:\n",
        "    # Determine the output folder name used in the previous cell\n",
        "    # (Assumes it was assigned to output_folder variable)\n",
        "    if 'output_folder' not in locals():\n",
        "         print(\"ERROR: 'output_folder' variable not found. Cannot determine zip filename.\")\n",
        "         zip_filename = \"all_geographies_wide_crosswalks.zip\" # Fallback name\n",
        "    else:\n",
        "         zip_filename = f\"all_geographies_wide_crosswalks_{os.path.basename(output_folder)}.zip\"\n",
        "\n",
        "\n",
        "    print(f\"\\nZipping {len(csv_files_generated)} generated CSV files into {zip_filename}...\")\n",
        "\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "            for file_path in tqdm(csv_files_generated, desc=\"Zipping files\"):\n",
        "                # Add file to zip using its basename to avoid including the folder path\n",
        "                if os.path.exists(file_path):\n",
        "                     zipf.write(file_path, arcname=os.path.basename(file_path))\n",
        "                else:\n",
        "                     print(f\"Warning: File not found, skipping zip: {file_path}\")\n",
        "\n",
        "        print(f\"Zip file created: {zip_filename}\")\n",
        "        print(\"Attempting to trigger download...\")\n",
        "        files.download(zip_filename)\n",
        "        print(\"Download initiated.\")\n",
        "\n",
        "    except FileNotFoundError as fnf_e:\n",
        "         print(f\"ERROR: File not found during zipping: {fnf_e}. Check file paths.\")\n",
        "    except Exception as zip_e:\n",
        "         print(f\"ERROR creating or downloading zip file: {zip_e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOrkw2D+in7gp1oB0KjXqh7",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
