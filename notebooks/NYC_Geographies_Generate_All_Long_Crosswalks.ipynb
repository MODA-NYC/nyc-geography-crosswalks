{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Note: This notebook now delegates to the reusable CLI\n",
        "\n",
        "This notebook has been wired to call the crosswalk builder module (`scripts/build_crosswalks.py`) for reproducibility.\n",
        "\n",
        "Steps:\n",
        "1. First run `generate_all_bounds.py` (or `python scripts/make_run.py`) to create a new `outputs/<run-id>/all_boundaries.geojson`.\n",
        "2. Run the code cell below to produce longform and wide crosswalk CSVs into the same run folder.\n",
        "\n",
        "You can still explore results in subsequent cells if desired.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, glob, subprocess\n",
        "\n",
        "# Find latest run directory\n",
        "runs = sorted([d for d in glob.glob('outputs/*') if os.path.isdir(d)])\n",
        "if not runs:\n",
        "    raise RuntimeError(\"No outputs/<run-id>/ found. Run generate_all_bounds.py or scripts/make_run.py first.\")\n",
        "latest = runs[-1]\n",
        "\n",
        "boundaries = os.path.join(latest, 'all_boundaries.geojson')\n",
        "if not os.path.isfile(boundaries):\n",
        "    raise RuntimeError(f\"Missing {boundaries}. Run bounds step first.\")\n",
        "\n",
        "print(f\"Using run folder: {latest}\")\n",
        "cmd = [\n",
        "    'python', 'scripts/build_crosswalks.py',\n",
        "    '--boundaries', boundaries,\n",
        "    '--run-dir', latest,\n",
        "]\n",
        "print('Running:', ' '.join(cmd))\n",
        "subprocess.run(cmd, check=True)\n",
        "print('Crosswalks built. See longform/ and wide/ under', latest)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MODA-NYC/nyc-geography-crosswalks/blob/main/NYC_Geographies_Generate_All_Long_Crosswalks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB7fdH-LRSID"
      },
      "source": [
        "# NYC Geographies: Generate All Long-Form Crosswalks\n",
        "\n",
        "This notebook automates the generation of comprehensive **long-form** geographic crosswalk tables for New York City. It processes all pairwise combinations of specified geographic boundaries using the `all_boundaries.geojson` file generated by the `generate_all_bounds.py` script.\n",
        "\n",
        "**Important:** This notebook relies on the `all_boundaries.geojson` file being generated first by the `generate_all_bounds.py` script located within this repository (`nyc-geography-crosswalks`). Ensure you have run that script and have access to its output file before running this notebook.\n",
        "\n",
        "**About the Input Data File:**\n",
        "The `all_boundaries.geojson` file used as input aggregates the same core NYC geographic boundaries previously used by the BetaNYC Boundaries Map project. The `generate_all_bounds.py` script aims to collect the **latest available versions** directly from their official sources at the time the script is run.\n",
        "\n",
        "*   **Note on Versions:** Currently, the specific version links (e.g., URLs containing `_25a` for data from NYC Planning's 2025 Cycle A update) are **hardcoded** within the generator script (`generate_all_bounds.py`).\n",
        "*   **Future Enhancement:** A potential future improvement could involve modifying the generator script to automatically check for and download the absolute latest versions available from the source portals.\n",
        "\n",
        "**Output:**\n",
        "The notebook produces multiple **long-form CSV files**, one for each primary geography type (e.g., `longform_cd_crosswalk.csv`, `longform_pp_crosswalk.csv`), saved into a timestamped output folder. Each file contains detailed rows for every significant intersection between that primary geography's features and features from *all other* geography types included in the input file. Each row includes:\n",
        "- Primary and Other Geography IDs and Names/Codes\n",
        "- Primary Feature Area (in sq ft)\n",
        "- Intersection Area (in sq ft, calculated using original, unbuffered geometries)\n",
        "- Percentage Overlap relative to the Primary Feature Area\n",
        "\n",
        "Finally, all generated CSV files are packaged into a single downloadable **ZIP archive** (e.g., `all_geographies_longform_crosswalks.zip`).\n",
        "\n",
        "### Workflow:\n",
        "1.  **Load Data:** Loads the pre-generated `all_boundaries.geojson` file (typically from Google Drive when using Colab - see Cell 3).\n",
        "2.  **Iterate:** Loops through each defined geography type as the \"primary\" geography.\n",
        "3.  **Calculate Intersections:** For each primary feature, calculates detailed geometric intersections with all features from *other* relevant geography types, using negative buffering to filter for significant overlaps.\n",
        "4.  **Generate CSVs:** Saves the consolidated long-form results for each primary geography into a separate CSV file within a dedicated, versioned output folder.\n",
        "5.  **Package Output:** Zips all generated CSV files from the current run into a single archive for download.\n",
        "\n",
        "### Data Sources:\n",
        "The **input** for *this notebook* is the `all_boundaries.geojson` file generated by the `generate_all_bounds.py` script. The **original sources** used by that script are:\n",
        "\n",
        "*   **cd (Community Districts):** NYC Department of City Planning (DCP)\n",
        "*   **pp (Police Precincts):** NYC Department of City Planning (DCP)\n",
        "*   **dsny (Sanitation Districts):** NYC Open Data (Dataset ID: i6mn-amj2)\n",
        "*   **fb (Fire Battalions):** NYC Department of City Planning (DCP)\n",
        "*   **sd (School Districts):** NYC Department of City Planning (DCP)\n",
        "*   **hc (Health Center Districts):** NYC Department of City Planning (DCP)\n",
        "*   **cc (City Council Districts):** NYC Department of City Planning (DCP)\n",
        "*   **nycongress (Congressional Districts):** NYC Department of City Planning (DCP)\n",
        "*   **sa (State Assembly Districts):** NYC Department of City Planning (DCP)\n",
        "*   **ss (State Senate Districts):** NYC Department of City Planning (DCP)\n",
        "*   **bid (Business Improvement Districts):** NYC Open Data (Dataset ID: 7jdm-inj8 / derived from ejxk-d93y)\n",
        "*   **nta (Neighborhood Tabulation Areas):** NYC Department of City Planning (DCP - NTA 2020)\n",
        "*   **zipcode (Modified Zip Code Tabulation Areas):** NYC Open Data (Dataset ID: pri4-ifjk)\n",
        "*   **hd (Historic Districts):** NYC Open Data (Dataset ID: skyk-mpzq / derived from xbvj-gfnw)\n",
        "*   **ibz (Industrial Business Zones):** NYC Economic Development Corporation (EDC)\n",
        "\n",
        "*Context for many planning datasets can be found at:*\n",
        "*   [NYC Planning - Bytes of the Big Apple](https://www.nyc.gov/site/planning/data-maps/open-data/bytes-big-apple.page)\n",
        "*   [NYC Open Data Portal](https://data.cityofnewyork.us/)\n",
        "\n",
        "### Requirements:\n",
        "- **Prerequisite:** Successful execution of `generate_all_bounds.py` and access to its output `all_boundaries.geojson`.\n",
        "- **Python Libraries:** `geopandas`, `pandas`, `tqdm`, `google.colab` (for Drive/files), `os`, `zipfile`. `requests` is needed if using the URL loading method for the data file.\n",
        "- **Environment:** Google Colab is recommended for Google Drive integration. Standard Python environments can also be used if data loading is adapted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdZpEvWghiFK"
      },
      "source": [
        "## 1: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fwG-L8ghZKd"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Install Dependencies\n",
        "# Install required libraries if running in a new environment\n",
        "print(\"Installing dependencies...\")\n",
        "!pip install geopandas pandas ipywidgets requests tqdm --quiet\n",
        "# Note: ipywidgets and requests might not be strictly needed if not using interactive elements\n",
        "# or the URL loading method, but including them based on previous context is safe.\n",
        "print(\"Dependencies installed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RigeOqPIhnh8"
      },
      "source": [
        "## 2: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXJmB1Bvhlah"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Import Libraries\n",
        "# Import necessary libraries for the entire notebook\n",
        "print(\"Importing libraries...\")\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "# import requests # Needed only if using URL method for data loading\n",
        "# from io import BytesIO # Needed only if using URL method for data loading\n",
        "from google.colab import drive # For loading from Google Drive\n",
        "from google.colab import files # For downloading results\n",
        "import zipfile # For packaging results\n",
        "from tqdm.notebook import tqdm # Progress bar\n",
        "import os\n",
        "from typing import Union # For type hints\n",
        "# Import necessary shapely ops if needed for union_all fallback\n",
        "# try:\n",
        "#     from shapely.ops import unary_union\n",
        "#     HAS_UNION_ALL = hasattr(gpd.GeoSeries([]).geometry, 'union_all')\n",
        "# except ImportError:\n",
        "#     HAS_UNION_ALL = False\n",
        "print(\"Libraries imported.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reZdaHVWhsMZ"
      },
      "source": [
        "## 3: Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iyn8GSThqU5"
      },
      "outputs": [],
      "source": [
        "# Cell 3: Load and Prepare Data\n",
        "# --- Load and Prepare the Master GeoDataFrame ---\n",
        "\n",
        "# Choose ONE of the methods below to load all_boundaries.geojson:\n",
        "\n",
        "# --- Method 1: Load from Google Drive (Currently Active for Testing) ---\n",
        "print(\"Attempting to mount Google Drive...\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# !!!! IMPORTANT: Replace this path with the ACTUAL path to your file on Google Drive !!!!\n",
        "geojson_path_on_drive = '/content/drive/MyDrive/Projects/ODA/Crosswalk Experiment/all_boundaries.geojson' # <--- CHANGE THIS\n",
        "\n",
        "gdf = None # Initialize gdf\n",
        "if not os.path.exists(geojson_path_on_drive):\n",
        "  print(f\"ERROR: File not found at specified Google Drive path: {geojson_path_on_drive}\")\n",
        "  print(\"Please double-check the path and ensure the file exists.\")\n",
        "else:\n",
        "  print(f\"Found file at: {geojson_path_on_drive}\")\n",
        "  try:\n",
        "      print(\"Reading GeoJSON from Google Drive...\")\n",
        "      gdf_loaded = gpd.read_file(geojson_path_on_drive)\n",
        "      print(f\"Successfully read file. Original CRS: {gdf_loaded.crs}\")\n",
        "\n",
        "      # Reproject to EPSG:2263 for buffer calculations in this notebook (feet)\n",
        "      print(\"Reprojecting to EPSG:2263 (Feet)...\")\n",
        "      gdf = gdf_loaded.to_crs(epsg=2263)\n",
        "      print(f\"Successfully loaded and reprojected GeoDataFrame. New CRS: {gdf.crs}\")\n",
        "\n",
        "      # Create Spatial Index for faster lookups\n",
        "      if gdf.sindex is None:\n",
        "          print(\"Generating spatial index for gdf...\")\n",
        "          gdf.sindex # This builds the index\n",
        "\n",
        "      print(\"\\nGeoDataFrame Info:\")\n",
        "      print(gdf.info())\n",
        "\n",
        "  except Exception as e:\n",
        "      print(f\"ERROR: Failed to read or reproject GeoJSON from Google Drive. Error: {e}\")\n",
        "      # raise e # Uncomment to stop execution on error\n",
        "\n",
        "# --- End Method 1 ---\n",
        "\n",
        "\n",
        "# --- Method 2: Load from URL (Currently Commented Out) ---\n",
        "# # !!!! IMPORTANT: Replace this URL with the ACTUAL download URL for your GeoJSON file !!!!\n",
        "# import requests # Need this if using URL method\n",
        "# from io import BytesIO # Need this if using URL method\n",
        "# geojson_url = \"YOUR_GEOJSON_DOWNLOAD_URL_HERE\" # <--- CHANGE THIS\n",
        "\n",
        "# gdf = None # Initialize gdf\n",
        "# try:\n",
        "#     print(f\"Attempting to download GeoJSON from URL: {geojson_url}\")\n",
        "#     response = requests.get(geojson_url, timeout=60)\n",
        "#     response.raise_for_status()\n",
        "#     print(\"Download successful. Reading GeoJSON...\")\n",
        "\n",
        "#     gdf_loaded = gpd.read_file(BytesIO(response.content))\n",
        "#     print(f\"Successfully read file. Original CRS: {gdf_loaded.crs}\")\n",
        "\n",
        "#     print(\"Reprojecting to EPSG:2263 (Feet)...\")\n",
        "#     gdf = gdf_loaded.to_crs(epsg=2263)\n",
        "#     print(f\"Successfully loaded and reprojected GeoDataFrame. New CRS: {gdf.crs}\")\n",
        "\n",
        "#     if gdf.sindex is None:\n",
        "#         print(\"Generating spatial index for gdf...\")\n",
        "#         gdf.sindex # Build index\n",
        "\n",
        "#     print(\"\\nGeoDataFrame Info:\")\n",
        "#     print(gdf.info())\n",
        "\n",
        "# except requests.exceptions.RequestException as e:\n",
        "#     print(f\"ERROR: Failed to download GeoJSON from URL. Error: {e}\")\n",
        "# except Exception as e:\n",
        "#     print(f\"ERROR: Failed to read or reproject GeoJSON from downloaded data. Error: {e}\")\n",
        "#     # raise e # Uncomment to stop execution on error\n",
        "\n",
        "# --- End Method 2 ---\n",
        "\n",
        "\n",
        "# --- Final Verification ---\n",
        "if 'gdf' not in locals() or gdf is None or not isinstance(gdf, gpd.GeoDataFrame) or gdf.empty:\n",
        "    raise ValueError(\"ERROR: GeoDataFrame 'gdf' was not loaded successfully in Cell 3. Cannot proceed.\")\n",
        "else:\n",
        "    print(\"\\nGeoDataFrame 'gdf' is loaded, prepared, and ready for use in subsequent cells.\")\n",
        "\n",
        "# --- Define Geography IDs list globally for use in next cell ---\n",
        "# (Corrected list based on previous steps)\n",
        "geography_ids = ['pp', 'fb', 'sd', 'bid', 'ibz', 'cd', 'dsny', 'hc',\n",
        "                 'cc', 'nycongress', 'sa', 'ss', 'nta', 'zipcode', 'hd']\n",
        "print(f\"\\nGeography IDs available for crosswalks: {geography_ids}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5Ksxhrvh-_4"
      },
      "source": [
        "## 4: Generate Long-Form Crosswalks (One File Per Primary Geography)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUZiWffih6lB"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Generate All Long-Form Crosswalks (One File Per Primary Geography)\n",
        "\n",
        "# Check if gdf and geography_ids exist from previous cell\n",
        "if 'gdf' not in locals() or gdf is None:\n",
        "     raise NameError(\"ERROR: GeoDataFrame 'gdf' is not available. Please run the 'Load and Prepare Data' cell first.\")\n",
        "if 'geography_ids' not in locals():\n",
        "     raise NameError(\"ERROR: 'geography_ids' list not found. Please run the 'Load and Prepare Data' cell first.\")\n",
        "if gdf.sindex is None: # Ensure spatial index exists\n",
        "    print(\"Warning: Spatial index not found on gdf. Generating now...\")\n",
        "    gdf.sindex\n",
        "\n",
        "print(\"Starting generation of consolidated long-form crosswalks (one file per primary geography)...\")\n",
        "\n",
        "# --- Configuration ---\n",
        "BUFFER_FEET = -200\n",
        "MIN_INTERSECTION_AREA_FILTER = 40 # Threshold for initial filtering based on buffered intersection\n",
        "\n",
        "# --- Output Setup ---\n",
        "output_folder = 'longform_crosswalks_consolidated' # New folder name\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "print(f\"Output CSVs will be saved to: {output_folder}\")\n",
        "csv_files_generated = [] # Keep track of generated files\n",
        "\n",
        "# Use the spatial index from the globally loaded gdf\n",
        "spatial_index = gdf.sindex\n",
        "\n",
        "# --- Main Loop: Iterate through each primary geography ---\n",
        "for primary_geo in tqdm(geography_ids, desc=\"Primary Geographies\"):\n",
        "    primary_gdf = gdf[gdf['id'] == primary_geo].copy()\n",
        "    if primary_gdf.empty:\n",
        "        print(f\"Skipping primary geography '{primary_geo}' - no features found.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nProcessing Primary Geography: {primary_geo}\")\n",
        "    # Initialize list to hold ALL intersection rows for THIS primary_geo\n",
        "    all_rows_for_this_primary = []\n",
        "\n",
        "    # Iterate through each feature of the primary geography\n",
        "    for _, primary_row in tqdm(primary_gdf.iterrows(), total=primary_gdf.shape[0], desc=f\"Features in {primary_geo}\", leave=False):\n",
        "        primary_name = primary_row['nameCol']\n",
        "        primary_geom_original = primary_row.geometry\n",
        "        primary_area = primary_geom_original.area\n",
        "        primary_geom_buffered = primary_geom_original.buffer(BUFFER_FEET)\n",
        "\n",
        "        if primary_area == 0: continue # Skip features with no area\n",
        "\n",
        "        # Find potential candidates intersecting the buffered primary feature's bounds\n",
        "        candidate_idx = list(spatial_index.intersection(primary_geom_buffered.bounds))\n",
        "        # Filter further: must intersect the actual buffered primary feature\n",
        "        # Exclude candidates that are the *same* primary geography type\n",
        "        candidate_features = gdf.iloc[candidate_idx][\n",
        "            (gdf.iloc[candidate_idx]['id'] != primary_geo) &\n",
        "            (gdf.iloc[candidate_idx].intersects(primary_geom_buffered))\n",
        "        ].copy()\n",
        "\n",
        "        if candidate_features.empty: continue # No potential overlaps for this primary feature\n",
        "\n",
        "        # Calculate intersection area with the BUFFERED primary geom for filtering small/touching overlaps\n",
        "        candidate_features['intersect_area_buffered'] = candidate_features.geometry.intersection(primary_geom_buffered).area\n",
        "        # Keep only candidates meeting the minimum buffered intersection area\n",
        "        target_candidates_filtered = candidate_features[candidate_features['intersect_area_buffered'] > MIN_INTERSECTION_AREA_FILTER]\n",
        "\n",
        "        if target_candidates_filtered.empty: continue # No significant overlaps after filtering\n",
        "\n",
        "        # Now, process these filtered candidates, grouping by their actual ID and nameCol\n",
        "        # Check if 'id' and 'nameCol' exist before grouping\n",
        "        if 'id' not in target_candidates_filtered.columns or 'nameCol' not in target_candidates_filtered.columns:\n",
        "             print(f\"Warning: 'id' or 'nameCol' missing in filtered candidates for primary feature {primary_name}. Skipping.\")\n",
        "             continue\n",
        "\n",
        "        # Group potential targets by their ID and nameCol to perform union before final intersection\n",
        "        grouped_targets = target_candidates_filtered.groupby(['id', 'nameCol'])\n",
        "\n",
        "        for (target_id, target_name_val), group in grouped_targets:\n",
        "            if pd.isna(target_name_val): continue # Skip if target name is missing\n",
        "\n",
        "            target_name_val_str = str(target_name_val) # Ensure string for consistency\n",
        "\n",
        "            # Union all geometries for this specific target ID and name\n",
        "            try:\n",
        "                union_geom = group.geometry.union_all()\n",
        "            except AttributeError:\n",
        "                union_geom = group.geometry.unary_union\n",
        "\n",
        "            # Calculate intersection with the ORIGINAL primary geometry\n",
        "            inter_geom = primary_geom_original.intersection(union_geom)\n",
        "            inter_area_final = inter_geom.area if not inter_geom.is_empty else 0\n",
        "            perc_overlap = (inter_area_final / primary_area) * 100 if primary_area > 0 else 0\n",
        "\n",
        "            # Add record only if there's some meaningful overlap area\n",
        "            if inter_area_final > 1e-6: # Use a small threshold\n",
        "                 row = {\n",
        "                     \"Primary Geography ID\": primary_geo,\n",
        "                     \"Primary Geography NameCol\": primary_name,\n",
        "                     \"Other Geography ID\": target_id,             # ID of the overlapping feature\n",
        "                     \"Other Geography NameCol\": target_name_val_str, # Name of the overlapping feature\n",
        "                     \"Primary Area (sq ft)\": primary_area,\n",
        "                     \"Intersection Area (sq ft)\": inter_area_final,\n",
        "                     \"Percentage Overlap\": perc_overlap\n",
        "                 }\n",
        "                 all_rows_for_this_primary.append(row)\n",
        "    # --- End loop for features within the primary geography ---\n",
        "\n",
        "    # --- Save the consolidated CSV for the current primary_geo ---\n",
        "    if all_rows_for_this_primary:\n",
        "        overlap_df = pd.DataFrame(all_rows_for_this_primary)\n",
        "        # Sort for clarity within the file\n",
        "        overlap_df = overlap_df.sort_values(\n",
        "            by=[\"Primary Geography NameCol\", \"Other Geography ID\", \"Percentage Overlap\"],\n",
        "            ascending=[True, True, False]\n",
        "        )\n",
        "\n",
        "        filename = f\"{output_folder}/longform_{primary_geo}_crosswalk.csv\"\n",
        "        try:\n",
        "            overlap_df.to_csv(filename, index=False)\n",
        "            csv_files_generated.append(filename)\n",
        "            print(f\"Saved consolidated file: {filename} ({len(overlap_df)} rows)\")\n",
        "        except Exception as save_e:\n",
        "            print(f\"ERROR saving {filename}: {save_e}\")\n",
        "    else:\n",
        "        print(f\"No significant overlaps found for primary geography {primary_geo}. No CSV generated.\")\n",
        "\n",
        "# --- End outer loop for primary geographies ---\n",
        "\n",
        "print(f\"\\nFinished generating all consolidated long-form crosswalk CSVs in folder: {output_folder}\")\n",
        "print(f\"Generated {len(csv_files_generated)} files.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsEG8G6uiGoS"
      },
      "source": [
        "## 5: Package and Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54sD6Ki9iDgB"
      },
      "outputs": [],
      "source": [
        "# Cell 5: Package and Download Results\n",
        "\n",
        "# Check if csv_files_generated exists and has files\n",
        "if 'csv_files_generated' not in locals() or not csv_files_generated:\n",
        "    print(\"No CSV files were generated in the previous step, skipping packaging.\")\n",
        "else:\n",
        "    # Zip and download the files\n",
        "    zip_filename = \"all_geographies_longform_crosswalks.zip\"\n",
        "    print(f\"\\nZipping {len(csv_files_generated)} generated CSV files into {zip_filename}...\")\n",
        "\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "            for file_path in tqdm(csv_files_generated, desc=\"Zipping files\"):\n",
        "                # Add file to zip using its basename to avoid including the folder path\n",
        "                zipf.write(file_path, arcname=os.path.basename(file_path))\n",
        "\n",
        "        print(f\"Zip file created: {zip_filename}\")\n",
        "        print(\"Attempting to trigger download...\")\n",
        "        files.download(zip_filename)\n",
        "        print(\"Download initiated.\")\n",
        "\n",
        "    except FileNotFoundError as fnf_e:\n",
        "         print(f\"ERROR: File not found during zipping: {fnf_e}. Check file paths.\")\n",
        "    except Exception as zip_e:\n",
        "         print(f\"ERROR creating or downloading zip file: {zip_e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSgetzOhmOAC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMJk6EmDkHs7OmqusNk2AlX",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
